{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9daf51d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import subprocess, os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3db1154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_vocals(input_path, output_dir=\"separated\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    subprocess.run([\n",
    "        \"python\", \"-m\", \"demucs.separate\",\n",
    "        \"--two-stems\", \"vocals\",\n",
    "        \"-o\", output_dir,\n",
    "        input_path\n",
    "    ], check=True)\n",
    "    name = os.path.splitext(os.path.basename(input_path))[0]\n",
    "    return os.path.join(output_dir, \"htdemucs\", name, \"vocals.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e12b4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mImportant: the default model was recently changed to `htdemucs`\u001b[0m the latest Hybrid Transformer Demucs model. In some cases, this model can actually perform worse than previous models. To get back the old default model use `-n mdx_extra_q`.\n",
      "Selected model is a bag of 1 models. You will see that many progress bars per track.\n",
      "Separated tracks will be stored in /Users/alexpower/Documents/Music-Dataset-Tool/Music/raw_vocals/htdemucs\n",
      "Separating track /Users/alexpower/Documents/Music-Dataset-Tool/Music/wav_files/waitingforlove-avicii.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 234.0/234.0 [01:34<00:00,  2.47seconds/s]\n",
      "/Users/alexpower/Documents/Music-Dataset-Tool/venv/lib/python3.13/site-packages/torchaudio/__init__.py:178: UserWarning: The 'encoding' parameter is not fully supported by TorchCodec AudioEncoder.\n",
      "  return save_with_torchcodec(\n",
      "/Users/alexpower/Documents/Music-Dataset-Tool/venv/lib/python3.13/site-packages/torchaudio/__init__.py:178: UserWarning: The 'bits_per_sample' parameter is not directly supported by TorchCodec AudioEncoder.\n",
      "  return save_with_torchcodec(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/alexpower/Documents/Music-Dataset-Tool/Music/raw_vocals/htdemucs/waitingforlove-avicii/vocals.wav'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = '../Music'\n",
    "song_path = 'wav_files/stargazing-kygo.wav'\n",
    "output_path = 'raw_vocals'\n",
    "\n",
    "final_song_path = os.path.join(base_path, song_path)\n",
    "final_output_path = os.path.join(base_path, output_path)\n",
    "\n",
    "input_path = os.path.abspath(\"../Music/wav_files/waitingforlove-avicii.wav\")\n",
    "output_dir = os.path.abspath(\"../Music/raw_vocals\")\n",
    "\n",
    "separate_vocals(input_path, output_dir)\n",
    "\n",
    "# this works extremely well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbef3d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c13bc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can use those vocals to more accurate check for vocals at a specific moment\n",
    "def vocal_activity_segments_spectral(vocals_path, frame_sec=0.25,\n",
    "                                     rms_factor=1.2, centroid_factor=0.9,\n",
    "                                     bandpass=True):\n",
    "    \"\"\"\n",
    "    Hybrid detector: uses RMS + spectral centroid to suppress background bleed.\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(vocals_path, sr=16000, mono=True)\n",
    "    frame_len = int(sr * frame_sec)\n",
    "    hop = frame_len // 2\n",
    "\n",
    "    if bandpass:\n",
    "        y = librosa.effects.preemphasis(y)  # mild high-freq emphasis\n",
    "        y = librosa.effects.hpss(y)[0]      # harmonic component only\n",
    "\n",
    "    rms = librosa.feature.rms(y=y, frame_length=frame_len, hop_length=hop)[0]\n",
    "    centroid = librosa.feature.spectral_centroid(y=y, sr=sr,\n",
    "                                                 n_fft=frame_len,\n",
    "                                                 hop_length=hop)[0]\n",
    "\n",
    "    times = librosa.frames_to_time(np.arange(len(rms)), sr=sr, hop_length=hop)\n",
    "\n",
    "    # Normalize both to [0,1] for stability\n",
    "    rms_n = (rms - rms.min()) / (rms.max() - rms.min() + 1e-9)\n",
    "    cent_n = (centroid - centroid.min()) / (centroid.max() - centroid.min() + 1e-9)\n",
    "\n",
    "    # Dynamic thresholds\n",
    "    rms_thr = np.median(rms_n) * rms_factor\n",
    "    cent_thr = np.median(cent_n) * centroid_factor\n",
    "\n",
    "    active = (rms_n > rms_thr) & (cent_n > cent_thr)\n",
    "    segments = []\n",
    "    start = None\n",
    "    for t, a in zip(times, active):\n",
    "        if a and start is None:\n",
    "            start = t\n",
    "        elif not a and start is not None:\n",
    "            segments.append((start, t))\n",
    "            start = None\n",
    "    if start is not None:\n",
    "        segments.append((start, times[-1]))\n",
    "\n",
    "    return segments\n",
    "\n",
    "def has_vocals_at(vocals_path, t, window=0.35, **kwargs):\n",
    "    segs = vocal_activity_segments_spectral(vocals_path, **kwargs)\n",
    "    start, end = t - window, t + window\n",
    "    return any(not (seg_end < start or seg_start > end)\n",
    "               for seg_start, seg_end in segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95b063d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_path = \"../Music/raw_vocals/htdemucs/waitingforlove-avicii/vocals.wav\"\n",
    "\n",
    "# since this expects 60 seconds to be 60.00, lets make a function that converts \n",
    "# minute times to seconds\n",
    "\n",
    "def time_to_secs(time):\n",
    "    str_representation = str(time)\n",
    "    minutes, seconds = str_representation.split(':')\n",
    "    \n",
    "    minutes = minutes[1]\n",
    "    \n",
    "    return float((int(minutes) * 60) + (int(seconds)))\n",
    "    \n",
    "# has_vocals_at(example_path, time_to_secs(1.40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab04a4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New file was created!\n"
     ]
    }
   ],
   "source": [
    "# so now we to devise a pipeline that for each song is results.join, gets the phrase boundaries,\n",
    "# finds the corresponding no_vocal track, check if vocals exist at that points, then export\n",
    "# lets make it so that phrase_boundary[i] corresponds to has_vocals[i]\n",
    "# have it so that we do not overwrite the current json, but instead just make a new file so we do not\n",
    "# corrupt the original\n",
    "import json\n",
    "import os\n",
    "\n",
    "json_path = os.path.abspath('../transition-results.json') \n",
    "raw_vocals_path = os.path.abspath('../Music/raw_vocals/htdemucs')\n",
    "\n",
    "# lets also just make these absolute as to not screw this up and have it work more broadly\n",
    "def update_json_phrase_boundaries_vocals(json_path, raw_vocals_path=None, output_path=None):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    # now foreach song, get the name and load both phrase boundaries\n",
    "    # song will be a dict here\n",
    "    songs = data['songs']\n",
    "    for song in songs:\n",
    "        song_name = song['song_name']\n",
    "        entry_phrase_boundaries = song['features']['first_phrase_boundaries']\n",
    "        exit_phrase_boundaries = song['features']['last_phrase_boundaries']\n",
    "        \n",
    "        # recall the phrase boundaries are in the format \"XX:XX\"\n",
    "        vocal_file_path = os.path.join(raw_vocals_path, song_name.replace(\".wav\", \"\"), 'vocals.wav')\n",
    "        \n",
    "        # the following could break if the len of entry and exit phrase boundaries is not the same\n",
    "        has_vocals_entry = []\n",
    "        has_vocals_exit = []\n",
    "        \n",
    "        for i in range(len(entry_phrase_boundaries)):\n",
    "            entry_bool = has_vocals_at(vocal_file_path, time_to_secs(entry_phrase_boundaries[i]))\n",
    "            exit_bool = has_vocals_at(vocal_file_path, time_to_secs(exit_phrase_boundaries[i]))\n",
    "            \n",
    "            has_vocals_entry.append(entry_bool)\n",
    "            has_vocals_exit.append(exit_bool)\n",
    "            \n",
    "        song['features']['entry_phrase_boundary_vocals'] = has_vocals_entry\n",
    "        song['features']['exit_phrase_boundary_vocals'] = has_vocals_exit\n",
    "    \n",
    "    base, ext = os.path.splitext(json_path)\n",
    "    output_path = base + \"_with_vocals\" + ext\n",
    "    \n",
    "    with open(output_path, 'w') as out:\n",
    "        json.dump(data, out, indent=2)\n",
    "        \n",
    "        \n",
    "    print('New file was created!')\n",
    "    \n",
    "        \n",
    "\n",
    "update_json_phrase_boundaries_vocals(json_path, raw_vocals_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e249692e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
